# ðŸš€ AI Content Studio - Deployment Guide

## Quick Deploy Options

### Option 1: Vercel (Frontend) + Render/Railway (Backend + ML)

#### Frontend (Vercel - Free)
```bash
# Build the frontend
cd frontend
npm run build

# Deploy to Vercel
npm i -g vercel
vercel deploy
```

#### Backend + ML Service (Render/Railway)
1. Push code to GitHub
2. Connect to Render.com or Railway.app
3. Set environment variables:
   - `PORT=5000` (backend)
   - `PORT=5001` (ML service)

---

### Option 2: Docker (Recommended)

```bash
# Build and run with Docker Compose
docker-compose up -d

# Or build individually
docker build -t ai-studio-backend ./backend
docker build -t ai-studio-ml ./ml-models
```

---

### Option 3: Cloud Hosting

#### AWS / GCP / Azure
1. Create VM instance (Ubuntu 20.04+)
2. Install Docker
3. Clone repository
4. Run: `docker-compose up -d`

#### DigitalOcean ($4/month)
```bash
# Create droplet
doctl compute droplet create ai-studio --size=s-2vcpu-4gb --image=ubuntu-20-04-x64

# SSH in and run
curl -fsSL https://get.docker.com | sh
docker-compose up -d
```

---

## Environment Setup for Production

### Backend (.env)
```env
PORT=5000
NODE_ENV=production
CORS_ORIGIN=https://your-domain.com
```

### ML Service (.env)
```env
PORT=5001
PYTHON_ENV=production
```

---

## WebGPU / Browser AI (Future)

For running AI directly in browser (no server needed):

1. Use **Transformers.js** - Run HuggingFace models in browser
2. Requires Chrome/Edge with WebGPU support
3. No server needed for inference

```javascript
// Example with Transformers.js
import { pipeline } = await import('@xenova/transformers');
const generator = await pipeline('text-to-image', 'stabilityai/stable-diffusion-2-1');
```

---

## Performance Notes

| Mode | Speed | Requirements |
|------|-------|--------------|
| CPU (Local) | 5-15 min/image | Just Python |
| GPU (Local) | 10-30 sec/image | NVIDIA GPU |
| Cloud GPU | 5-15 sec/image | $10+/month |
| WebGPU | Varies | Chrome + GPU |

---

## Recommended Hosting Stack

1. **Frontend**: Vercel (free)
2. **Backend API**: Railway ($5/month)
3. **ML Service**: Railway with GPU ($20/month) or RunPod

---

## SSL/HTTPS Setup

1. Buy domain or use free: `.vercel.app`, `.railway.app`
2. Auto-generated by hosting platforms
3. Or use Cloudflare (free SSL)

---

## Troubleshooting

### CORS Issues
- Update CORS_ORIGIN in backend
- Use full domain URL in production

### Memory Issues
- Use smaller models
- Add swap space: `sudo fallocate -l 4G /swapfile`

### Slow Performance
- Use GPU instance
- Cache models locally
- Use CDN for static files
