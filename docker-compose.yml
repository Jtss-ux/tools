version: '3.8'

services:
  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    environment:
      - PORT=5000
    volumes:
      - ./backend/uploads:/app/uploads
    networks:
      - ai-studio

  # Python ML Service
  ml-service:
    build:
      context: ./ml-models
      dockerfile: Dockerfile
    ports:
      - "5001:5001"
    environment:
      - FLASK_ENV=production
      - PORT=5001
    volumes:
      - ./ml-models/models:/app/models
    networks:
      - ai-studio

  # Frontend (optional - you can run locally too)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    networks:
      - ai-studio
    depends_on:
      - backend
      - ml-service

networks:
  ai-studio:
    driver: bridge
